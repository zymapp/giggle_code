# ä¸€ã€whisper éƒ¨ç½²

## ğŸ§© 1ã€ç³»ç»Ÿç¯å¢ƒ

âœ… ç³»ç»Ÿç¯å¢ƒ
```
æ“ä½œç³»ç»Ÿ	Ubuntu Server 22.04 LTS 64ä½
CPU	8æ ¸
å†…å­˜	32GB
GPU	1 * NVIDIA T4  
```  

## ğŸ§© 2ã€whisper éƒ¨ç½²æ­¥éª¤

1ï¸âƒ£ å®‰è£… NVIDIA é©±åŠ¨ + CUDA å·¥å…·é“¾
```
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade

# å®‰è£…ä¾èµ–
sudo apt install build-essential dkms

# æ·»åŠ  CUDA ä»“åº“å¹¶å®‰è£…ï¼ˆä»¥ CUDA 11.8 ä¸ºä¾‹ï¼‰
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2004-11-8-local_11.8.0-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-11-8-local_11.8.0-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2004-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt update
sudo apt install cuda

# æ·»åŠ åˆ°ç¯å¢ƒå˜é‡
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

2ï¸âƒ£ å®‰è£… Python ç¯å¢ƒå’Œä¾èµ–
```
# å®‰è£… Python å’Œ venv
sudo apt install python3 python3-pip python3-venv

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv whisper-env
source whisper-env/bin/activate

# å‡çº§ pip
pip install --upgrade pip
```

3ï¸âƒ£ å®‰è£… PyTorchï¼ˆGPU ç‰ˆæœ¬ï¼‰
è®¿é—® https://pytorch.org/get-started/locally/ï¼Œé€‰æ‹©é€‚åˆä½  CUDA ç‰ˆæœ¬çš„å‘½ä»¤ï¼ˆå¦‚ CUDA 11.8ï¼‰ï¼š
```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
éªŒè¯æ˜¯å¦ä½¿ç”¨ GPUï¼š
```
# åœ¨ python ä¸­æ‰§è¡Œ
import torch
print(torch.cuda.is_available())  # True è¡¨ç¤ºæˆåŠŸ
```

4ï¸âƒ£ å®‰è£… Whisper å¹¶æµ‹è¯• GPU åŠ é€Ÿ
```
pip install git+https://github.com/openai/whisper.git
```

5ï¸âƒ£ æµ‹è¯•ï¼š
```
whisper example.mp3 --model medium --device cuda
```
å¦‚æœè¿è¡Œæ—¶ GPU è¢«ä½¿ç”¨ï¼Œä¼šçœ‹åˆ°æ˜æ˜¾åŠ é€Ÿã€‚

## ğŸ§© 3ã€å°†whisper éƒ¨ç½²ä¸º API æœåŠ¡ï¼ˆä½¿ç”¨ FastAPIï¼‰

1ï¸âƒ£ å®‰è£…uvicorn
```
pip install fastapi uvicorn
```

2ï¸âƒ£ åˆ›å»º app.pyï¼š
```
from fastapi import FastAPI, UploadFile, File
import whisper
import tempfile

app = FastAPI()
model = whisper.load_model("medium", device="cuda")

@app.post("/transcribe/")
async def transcribe(file: UploadFile = File(...)):
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name
    result = model.transcribe(tmp_path)
    return {"text": result["text"]}
```

3ï¸âƒ£ å¯åŠ¨ APIï¼š
```
uvicorn app:app --host 0.0.0.0 --port 8000
or
nohup python -m uvicorn app:app --host 0.0.0.0 --port 8000 > uvicorn.log 2>&1 &
```

4ï¸âƒ£ æŸ¥çœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸ
ps aux | grep uvicorn


5ï¸âƒ£ æµ‹è¯•whisperæ¥å£ï¼š
```
curl -X POST "http://localhost:8000/transcribe/" \
  -F "file=@your_audio_file.mp3"
```
è¿”å›ä»¥ä¸‹ç»“æœä»£è¡¨ whisperçš„ç¯å¢ƒæˆåŠŸ
![image](https://github.com/user-attachments/assets/f3c926c1-0663-413d-ad1a-94917444a23f)

æ–‡æ¡£åœ°å€åœ¨ 8000/docsï¼Œå¦‚ä¸‹ï¼š
<img width="1470" alt="image" src="https://github.com/user-attachments/assets/d2e32245-84ea-4076-adb6-be11fdfab432" />


âœ… éªŒè¯ GPU æ˜¯å¦å·¥ä½œä¸­
```
nvidia-smi
```
ä½ åº”è¯¥çœ‹åˆ° Python æˆ–è€… uvicorn è¿›ç¨‹æ­£åœ¨ä½¿ç”¨ GPUã€‚

# äºŒã€javaæœåŠ¡éƒ¨ç½²

<img width="1384" alt="image" src="https://github.com/user-attachments/assets/de2f9da9-803a-4a79-822c-630803797b3a" />

![image](https://github.com/user-attachments/assets/d6e03a5f-f001-4c4d-b248-6136779cf176)

![image](https://github.com/user-attachments/assets/2313a902-1837-4847-937a-78b906669cfc)


